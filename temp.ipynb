{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import accelerate\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.checkpoint\n",
    "import transformers\n",
    "from accelerate import Accelerator\n",
    "from accelerate.logging import get_logger\n",
    "from datetime import timedelta\n",
    "from accelerate.utils import ProjectConfiguration, set_seed, InitProcessGroupKwargs\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import HfFolder, Repository, create_repo, whoami\n",
    "from packaging import version\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import PretrainedConfig, CLIPTextModel, CLIPTokenizer, CLIPImageProcessor\n",
    "\n",
    "import diffusers\n",
    "from diffusers import (\n",
    "    AutoencoderKL,\n",
    "    ControlNetModel,\n",
    "    DDPMScheduler,\n",
    "    StableDiffusionControlNetPipeline,\n",
    "    UNet2DConditionModel,\n",
    "    PNDMScheduler\n",
    ")\n",
    "\n",
    "from diffusers.optimization import get_scheduler\n",
    "from diffusers.utils import check_min_version, is_wandb_available\n",
    "from diffusers.utils.import_utils import is_xformers_available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_vae_path = \"/blob/v-yuancwang/AudioEditingModel/VAE_GAN/checkpoint-40000\"\n",
    "vae = AutoencoderKL.from_pretrained(audio_vae_path, subfolder=\"vae\")\n",
    "torch_device = \"cuda:1\"\n",
    "vae.to(torch_device)\n",
    "vae.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-28N8VI2emM_76000_86000.wav'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_wav_path = \"/blob/v-yuancwang/DiffAudioImg/VGGSound/data/vggsound/wav\"\n",
    "vgg_mel_path = \"/blob/v-yuancwang/DiffAudioImg/VGGSound/data/vggsound/mel\"\n",
    "mel_id = \"-28N8VI2emM_76000_86000.npy\"\n",
    "test_mel = np.load(os.path.join(vgg_mel_path, mel_id))\n",
    "wav_id = mel_id.replace(\".npy\", \".wav\")\n",
    "np.save(os.path.join(\"/home/v-yuancwang/DiffAudioImg/test_vae_mel\", mel_id[:-4]+\"_gt_mel\"+\".npy\"), test_mel)\n",
    "Audio(os.path.join(vgg_wav_path, wav_id))\n",
    "copy(os.path.join(vgg_wav_path, wav_id), wav_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_mel)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_input = torch.tensor(test_mel[:,:624]).to(torch_device).reshape(1, 1, 80, 624)\n",
    "print(vae_input.shape)\n",
    "with torch.no_grad():\n",
    "    posterior = vae.encode(vae_input).latent_dist\n",
    "    z = posterior.sample()\n",
    "    vae_output = vae.decode(z).sample\n",
    "vae_output_np = vae_output.cpu().numpy()[0][0]\n",
    "# print(test_mel)\n",
    "# print(np.mean(test_mel[:,:624] - vae_output_np))\n",
    "plt.imshow(vae_output_np)\n",
    "plt.show()\n",
    "np.save(os.path.join(\"/home/v-yuancwang/DiffAudioImg/test_vae_mel\", mel_id), vae_output_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Image Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_id = \"2/--EquRwM9IQ_8000_18000_2.jpg\"\n",
    "image = Image.open(os.path.join(\"/blob/v-yuancwang/DiffAudioImg/VGGSound/data/vggsound/img_spilt\", img_id))\n",
    "image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "control",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
